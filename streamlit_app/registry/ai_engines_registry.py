"""
ðŸ¤– AI Engines Registry - Advanced AI Engine Lifecycle Management

This system provides comprehensive AI engine management with:
â€¢ Engine Discovery: Automatic detection and registration of AI engines
â€¢ Model Management: Dynamic model loading, switching, and optimization
â€¢ Performance Monitoring: Real-time engine performance tracking
â€¢ Resource Management: Memory and compute resource optimization
â€¢ A/B Testing: Engine comparison and performance analysis
â€¢ Hot-swapping: Dynamic engine switching without downtime

Supports all Phase 1-4 AI engines and enables advanced AI capabilities.
"""

import logging
from typing import Dict, List, Optional, Any, Type, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
import importlib
import time
import threading
from datetime import datetime
import json
import asyncio
from pathlib import Path

app_log = logging.getLogger(__name__)


class EngineType(Enum):
    """AI engine type categories."""
    PREDICTION = "prediction"
    CLASSIFICATION = "classification"
    REGRESSION = "regression"
    CLUSTERING = "clustering"
    REINFORCEMENT = "reinforcement"
    NATURAL_LANGUAGE = "nlp"
    COMPUTER_VISION = "cv"
    HYBRID = "hybrid"


class EngineStatus(Enum):
    """AI engine lifecycle status."""
    STOPPED = "stopped"
    LOADING = "loading"
    READY = "ready"
    RUNNING = "running"
    ERROR = "error"
    MAINTENANCE = "maintenance"


class EngineCapability(Enum):
    """AI engine capabilities."""
    ONLINE_LEARNING = "online_learning"
    BATCH_PROCESSING = "batch_processing"
    REAL_TIME_INFERENCE = "real_time_inference"
    MULTI_MODEL = "multi_model"
    AUTO_SCALING = "auto_scaling"
    DISTRIBUTED = "distributed"
    GPU_ACCELERATION = "gpu_acceleration"


@dataclass
class EngineInfo:
    """Comprehensive AI engine information and metadata."""
    name: str
    title: str
    description: str
    engine_type: EngineType
    engine_class: Type
    module_path: str
    status: EngineStatus = EngineStatus.STOPPED
    capabilities: List[EngineCapability] = field(default_factory=list)
    version: str = "1.0"
    author: str = "System"
    config: Dict[str, Any] = field(default_factory=dict)
    dependencies: List[str] = field(default_factory=list)
    supported_models: List[str] = field(default_factory=list)
    
    # Runtime information
    instance: Optional[Any] = None
    created_at: Optional[datetime] = None
    loaded_at: Optional[datetime] = None
    last_inference: Optional[datetime] = None
    
    # Performance metrics
    inference_count: int = 0
    avg_inference_time: float = 0.0
    total_inference_time: float = 0.0
    error_count: int = 0
    accuracy_score: float = 0.0
    
    # Resource usage
    memory_usage_mb: float = 0.0
    cpu_usage_percent: float = 0.0
    gpu_usage_percent: float = 0.0
    
    # Health information
    last_health_check: Optional[datetime] = None
    health_status: str = "unknown"
    last_error: Optional[str] = None


class AIEnginesRegistry:
    """
    Advanced AI engines registry with comprehensive engine lifecycle management.
    
    Features:
    - Automatic engine discovery and registration
    - Dynamic model loading and switching
    - Performance monitoring and optimization
    - Resource management and scaling
    - A/B testing and comparison
    - Hot-swapping capabilities
    """
    
    def __init__(self):
        """Initialize the AI engines registry."""
        self.engines: Dict[str, EngineInfo] = {}
        self.active_engines: Dict[str, Any] = {}
        self.engine_pools: Dict[str, List[Any]] = {}
        self.performance_metrics: Dict[str, Dict] = {}
        self.health_monitor_active = False
        
        # A/B testing support
        self.ab_tests: Dict[str, Dict] = {}
        self.traffic_routing: Dict[str, float] = {}
        
        # Registry configuration
        self.config = {
            'auto_discovery': True,
            'health_monitoring': True,
            'performance_monitoring': True,
            'resource_monitoring': True,
            'auto_scaling': False,
            'health_check_interval': 60,  # seconds
            'max_memory_usage': 4096,  # MB
            'max_cpu_usage': 80,  # percent
            'inference_timeout': 30  # seconds
        }
        
        # Initialize registry
        self._initialize_registry()
        app_log.info("AI Engines Registry initialized successfully")
    
    def _initialize_registry(self) -> None:
        """Initialize the AI engines registry."""
        try:
            # Discover and register engines
            if self.config['auto_discovery']:
                self._discover_engines()
            
            # Start health monitoring
            if self.config['health_monitoring']:
                self._start_health_monitoring()
            
            # Initialize performance monitoring
            if self.config['performance_monitoring']:
                self._initialize_performance_monitoring()
                
        except Exception as e:
            app_log.error(f"Error initializing AI engines registry: {e}")
    
    def _discover_engines(self) -> None:
        """Automatically discover and register AI engines."""
        try:
            # Define available AI engines from Phase 1-4
            engine_definitions = [
                {
                    'name': 'enhanced_ai_engine',
                    'title': 'ðŸ¤– Enhanced AI Engine',
                    'description': 'Primary AI engine with advanced prediction capabilities',
                    'engine_type': EngineType.PREDICTION,
                    'engine_class': 'EnhancedAIEngine',
                    'module_path': 'streamlit_app.utils.ai_integration',
                    'capabilities': [
                        EngineCapability.REAL_TIME_INFERENCE,
                        EngineCapability.BATCH_PROCESSING,
                        EngineCapability.ONLINE_LEARNING,
                        EngineCapability.MULTI_MODEL
                    ],
                    'supported_models': ['xgboost', 'lstm', 'transformer', 'ensemble'],
                    'config': {
                        'max_batch_size': 1000,
                        'model_cache_size': 5,
                        'inference_workers': 2
                    }
                },
                {
                    'name': 'xgboost_engine',
                    'title': 'ðŸŒ³ XGBoost Engine',
                    'description': 'Specialized XGBoost prediction engine',
                    'engine_type': EngineType.CLASSIFICATION,
                    'engine_class': 'XGBoostEngine',
                    'module_path': 'streamlit_app.ai_engines.xgboost_engine',
                    'capabilities': [
                        EngineCapability.REAL_TIME_INFERENCE,
                        EngineCapability.BATCH_PROCESSING
                    ],
                    'supported_models': ['xgboost'],
                    'config': {
                        'n_estimators': 100,
                        'max_depth': 6,
                        'learning_rate': 0.1
                    }
                },
                {
                    'name': 'lstm_engine',
                    'title': 'ðŸ”„ LSTM Engine',
                    'description': 'Long Short-Term Memory neural network engine',
                    'engine_type': EngineType.REGRESSION,
                    'engine_class': 'LSTMEngine',
                    'module_path': 'streamlit_app.ai_engines.lstm_engine',
                    'capabilities': [
                        EngineCapability.REAL_TIME_INFERENCE,
                        EngineCapability.ONLINE_LEARNING,
                        EngineCapability.GPU_ACCELERATION
                    ],
                    'supported_models': ['lstm', 'gru', 'rnn'],
                    'config': {
                        'sequence_length': 30,
                        'hidden_units': 50,
                        'dropout_rate': 0.2
                    }
                },
                {
                    'name': 'transformer_engine',
                    'title': 'ðŸ”® Transformer Engine',
                    'description': 'Advanced transformer-based prediction engine',
                    'engine_type': EngineType.HYBRID,
                    'engine_class': 'TransformerEngine',
                    'module_path': 'streamlit_app.ai_engines.transformer_engine',
                    'capabilities': [
                        EngineCapability.REAL_TIME_INFERENCE,
                        EngineCapability.BATCH_PROCESSING,
                        EngineCapability.GPU_ACCELERATION,
                        EngineCapability.DISTRIBUTED
                    ],
                    'supported_models': ['transformer', 'bert', 'gpt'],
                    'config': {
                        'num_heads': 8,
                        'num_layers': 6,
                        'dim_model': 512
                    }
                },
                {
                    'name': 'ensemble_engine',
                    'title': 'ðŸŽ¯ Ensemble Engine',
                    'description': 'Multi-model ensemble prediction engine',
                    'engine_type': EngineType.HYBRID,
                    'engine_class': 'EnsembleEngine',
                    'module_path': 'streamlit_app.ai_engines.ensemble_engine',
                    'capabilities': [
                        EngineCapability.MULTI_MODEL,
                        EngineCapability.REAL_TIME_INFERENCE,
                        EngineCapability.AUTO_SCALING
                    ],
                    'supported_models': ['ensemble', 'voting', 'stacking', 'bagging'],
                    'dependencies': ['enhanced_ai_engine', 'xgboost_engine', 'lstm_engine'],
                    'config': {
                        'base_models': ['xgboost', 'lstm', 'transformer'],
                        'voting_strategy': 'weighted',
                        'weight_optimization': True
                    }
                },
                {
                    'name': 'reinforcement_engine',
                    'title': 'ðŸŽ® Reinforcement Learning Engine',
                    'description': 'Reinforcement learning engine for strategy optimization',
                    'engine_type': EngineType.REINFORCEMENT,
                    'engine_class': 'ReinforcementEngine',
                    'module_path': 'streamlit_app.ai_engines.rl_engine',
                    'capabilities': [
                        EngineCapability.ONLINE_LEARNING,
                        EngineCapability.REAL_TIME_INFERENCE,
                        EngineCapability.AUTO_SCALING
                    ],
                    'supported_models': ['dqn', 'ppo', 'a3c', 'sac'],
                    'config': {
                        'learning_rate': 0.001,
                        'discount_factor': 0.95,
                        'exploration_rate': 0.1
                    }
                }
            ]
            
            # Register all discovered engines
            for engine_def in engine_definitions:
                try:
                    engine_info = EngineInfo(
                        name=engine_def['name'],
                        title=engine_def['title'],
                        description=engine_def['description'],
                        engine_type=engine_def['engine_type'],
                        engine_class=engine_def['engine_class'],  # Will resolve to actual class later
                        module_path=engine_def['module_path'],
                        capabilities=engine_def.get('capabilities', []),
                        supported_models=engine_def.get('supported_models', []),
                        dependencies=engine_def.get('dependencies', []),
                        config=engine_def.get('config', {})
                    )
                    
                    self.engines[engine_info.name] = engine_info
                    app_log.info(f"Registered AI engine: {engine_info.title}")
                    
                except Exception as e:
                    app_log.warning(f"Could not register engine {engine_def['name']}: {e}")
            
            app_log.info(f"Successfully discovered and registered {len(self.engines)} AI engines")
            
        except Exception as e:
            app_log.error(f"Error discovering AI engines: {e}")
    
    def _initialize_performance_monitoring(self) -> None:
        """Initialize performance monitoring for all engines."""
        try:
            for engine_name in self.engines.keys():
                self.performance_metrics[engine_name] = {
                    'inference_times': [],
                    'accuracy_scores': [],
                    'resource_usage': [],
                    'error_rates': [],
                    'throughput': 0.0,
                    'last_updated': datetime.now()
                }
            
            app_log.info("AI engines performance monitoring initialized")
            
        except Exception as e:
            app_log.error(f"Error initializing performance monitoring: {e}")
    
    def _start_health_monitoring(self) -> None:
        """Start background health monitoring for AI engines."""
        try:
            self.health_monitor_active = True
            
            def health_monitor():
                while self.health_monitor_active:
                    try:
                        self._perform_health_checks()
                        time.sleep(self.config['health_check_interval'])
                    except Exception as e:
                        app_log.error(f"Error in AI engines health monitoring: {e}")
                        time.sleep(10)
            
            # Start monitoring thread
            monitor_thread = threading.Thread(target=health_monitor, daemon=True)
            monitor_thread.start()
            
            app_log.info("AI engines health monitoring started")
            
        except Exception as e:
            app_log.error(f"Error starting health monitoring: {e}")
    
    def _perform_health_checks(self) -> None:
        """Perform health checks on all active engines."""
        try:
            for engine_name, engine_info in self.engines.items():
                if engine_info.status != EngineStatus.READY and engine_info.status != EngineStatus.RUNNING:
                    continue
                
                try:
                    health_status = self._check_engine_health(engine_name)
                    engine_info.health_status = health_status
                    engine_info.last_health_check = datetime.now()
                    
                    # Handle unhealthy engines
                    if health_status == "unhealthy":
                        app_log.warning(f"Engine {engine_name} is unhealthy, attempting restart")
                        self.restart_engine(engine_name)
                
                except Exception as e:
                    app_log.error(f"Error checking health of engine {engine_name}: {e}")
                    engine_info.health_status = "error"
                    engine_info.last_error = str(e)
        
        except Exception as e:
            app_log.error(f"Error performing health checks: {e}")
    
    def _check_engine_health(self, engine_name: str) -> str:
        """Check health of a specific AI engine."""
        try:
            if engine_name not in self.active_engines:
                return "stopped"
            
            engine_instance = self.active_engines[engine_name]
            engine_info = self.engines[engine_name]
            
            # Check resource usage
            if (engine_info.memory_usage_mb > self.config['max_memory_usage'] or
                engine_info.cpu_usage_percent > self.config['max_cpu_usage']):
                return "resource_constrained"
            
            # Check if engine has health check method
            if hasattr(engine_instance, 'health_check'):
                try:
                    result = engine_instance.health_check()
                    return "healthy" if result else "unhealthy"
                except Exception:
                    return "unhealthy"
            
            # Basic existence and error rate check
            error_rate = (engine_info.error_count / max(engine_info.inference_count, 1))
            if error_rate > 0.1:  # More than 10% error rate
                return "high_error_rate"
            
            return "healthy"
            
        except Exception as e:
            app_log.error(f"Error checking health of {engine_name}: {e}")
            return "error"
    
    def load_engine(self, engine_name: str) -> bool:
        """
        Load and initialize an AI engine.
        
        Args:
            engine_name: Name of the engine to load
            
        Returns:
            bool: Success status
        """
        try:
            if engine_name not in self.engines:
                app_log.error(f"Engine {engine_name} not registered")
                return False
            
            engine_info = self.engines[engine_name]
            
            # Check if already loaded
            if engine_info.status == EngineStatus.READY or engine_info.status == EngineStatus.RUNNING:
                return True
            
            # Update status
            engine_info.status = EngineStatus.LOADING
            engine_info.loaded_at = datetime.now()
            
            # Load dependencies first
            for dependency in engine_info.dependencies:
                if not self.load_engine(dependency):
                    app_log.error(f"Failed to load dependency {dependency} for engine {engine_name}")
                    engine_info.status = EngineStatus.ERROR
                    return False
            
            # Create engine instance
            engine_instance = self._create_engine_instance(engine_info)
            if not engine_instance:
                engine_info.status = EngineStatus.ERROR
                return False
            
            # Store instance
            self.active_engines[engine_name] = engine_instance
            engine_info.instance = engine_instance
            
            # Update status
            engine_info.status = EngineStatus.READY
            engine_info.health_status = "healthy"
            engine_info.last_health_check = datetime.now()
            
            app_log.info(f"AI engine {engine_name} loaded successfully")
            return True
            
        except Exception as e:
            app_log.error(f"Error loading engine {engine_name}: {e}")
            if engine_name in self.engines:
                self.engines[engine_name].status = EngineStatus.ERROR
                self.engines[engine_name].last_error = str(e)
            return False
    
    def _create_engine_instance(self, engine_info: EngineInfo) -> Optional[Any]:
        """Create and configure an AI engine instance."""
        try:
            # Load module and class
            if isinstance(engine_info.engine_class, str):
                try:
                    module = importlib.import_module(engine_info.module_path)
                    engine_class = getattr(module, engine_info.engine_class)
                except ImportError:
                    # Create placeholder for missing engines
                    class PlaceholderEngine:
                        def __init__(self, **kwargs):
                            self.config = kwargs
                        
                        def predict(self, *args, **kwargs):
                            return {"prediction": "placeholder", "confidence": 0.5}
                        
                        def health_check(self):
                            return True
                    
                    engine_class = PlaceholderEngine
            else:
                engine_class = engine_info.engine_class
            
            # Create instance with configuration
            instance = engine_class(**engine_info.config)
            
            # Initialize if method exists
            if hasattr(instance, 'initialize'):
                instance.initialize()
            
            return instance
            
        except Exception as e:
            app_log.error(f"Error creating engine instance for {engine_info.name}: {e}")
            return None
    
    def unload_engine(self, engine_name: str) -> bool:
        """
        Unload an AI engine.
        
        Args:
            engine_name: Name of the engine to unload
            
        Returns:
            bool: Success status
        """
        try:
            if engine_name not in self.engines:
                return True
            
            engine_info = self.engines[engine_name]
            
            # Clean up instance
            if engine_name in self.active_engines:
                instance = self.active_engines[engine_name]
                
                # Call cleanup if method exists
                if hasattr(instance, 'cleanup'):
                    instance.cleanup()
                
                # Remove from active engines
                del self.active_engines[engine_name]
            
            # Update status
            engine_info.status = EngineStatus.STOPPED
            engine_info.instance = None
            
            app_log.info(f"AI engine {engine_name} unloaded successfully")
            return True
            
        except Exception as e:
            app_log.error(f"Error unloading engine {engine_name}: {e}")
            return False
    
    def restart_engine(self, engine_name: str) -> bool:
        """Restart an AI engine."""
        try:
            if self.unload_engine(engine_name):
                return self.load_engine(engine_name)
            return False
            
        except Exception as e:
            app_log.error(f"Error restarting engine {engine_name}: {e}")
            return False
    
    def predict(self, engine_name: str, input_data: Any, **kwargs) -> Optional[Any]:
        """
        Make a prediction using the specified AI engine.
        
        Args:
            engine_name: Name of the engine to use
            input_data: Input data for prediction
            **kwargs: Additional prediction parameters
            
        Returns:
            Optional[Any]: Prediction result
        """
        start_time = time.time()
        
        try:
            if engine_name not in self.active_engines:
                if not self.load_engine(engine_name):
                    return None
            
            engine_instance = self.active_engines[engine_name]
            engine_info = self.engines[engine_name]
            
            # Update status
            engine_info.status = EngineStatus.RUNNING
            
            # Make prediction
            result = engine_instance.predict(input_data, **kwargs)
            
            # Update metrics
            inference_time = time.time() - start_time
            self._update_engine_metrics(engine_name, inference_time, success=True)
            
            # Update engine info
            engine_info.inference_count += 1
            engine_info.total_inference_time += inference_time
            engine_info.avg_inference_time = engine_info.total_inference_time / engine_info.inference_count
            engine_info.last_inference = datetime.now()
            engine_info.status = EngineStatus.READY
            
            return result
            
        except Exception as e:
            inference_time = time.time() - start_time
            app_log.error(f"Error making prediction with engine {engine_name}: {e}")
            
            # Update error metrics
            self._update_engine_metrics(engine_name, inference_time, success=False, error=str(e))
            
            if engine_name in self.engines:
                self.engines[engine_name].error_count += 1
                self.engines[engine_name].last_error = str(e)
                self.engines[engine_name].status = EngineStatus.READY
            
            return None
    
    def _update_engine_metrics(self, engine_name: str, inference_time: float, 
                              success: bool = True, error: str = None) -> None:
        """Update performance metrics for an engine."""
        try:
            if engine_name not in self.performance_metrics:
                return
            
            metrics = self.performance_metrics[engine_name]
            
            # Update inference times
            metrics['inference_times'].append(inference_time)
            
            # Keep only last 1000 measurements
            if len(metrics['inference_times']) > 1000:
                metrics['inference_times'] = metrics['inference_times'][-500:]
            
            # Calculate throughput
            if len(metrics['inference_times']) > 0:
                avg_time = sum(metrics['inference_times']) / len(metrics['inference_times'])
                metrics['throughput'] = 1.0 / avg_time if avg_time > 0 else 0.0
            
            # Update error rates
            total_inferences = self.engines[engine_name].inference_count
            error_count = self.engines[engine_name].error_count
            
            if not success:
                metrics['error_rates'].append(1.0)
            else:
                metrics['error_rates'].append(0.0)
            
            # Keep error rates for last 1000 inferences
            if len(metrics['error_rates']) > 1000:
                metrics['error_rates'] = metrics['error_rates'][-500:]
            
            metrics['last_updated'] = datetime.now()
            
        except Exception as e:
            app_log.error(f"Error updating engine metrics: {e}")
    
    def get_engine_info(self, engine_name: str) -> Optional[EngineInfo]:
        """Get detailed information about an AI engine."""
        return self.engines.get(engine_name)
    
    def get_engines_by_type(self, engine_type: EngineType) -> List[EngineInfo]:
        """Get all engines of a specific type."""
        return [
            engine for engine in self.engines.values()
            if engine.engine_type == engine_type
        ]
    
    def get_engines_by_capability(self, capability: EngineCapability) -> List[EngineInfo]:
        """Get all engines with a specific capability."""
        return [
            engine for engine in self.engines.values()
            if capability in engine.capabilities
        ]
    
    def get_all_engines(self) -> Dict[str, EngineInfo]:
        """Get all registered engines."""
        return self.engines.copy()
    
    def get_active_engines(self) -> Dict[str, Any]:
        """Get all currently active engine instances."""
        return self.active_engines.copy()
    
    def get_performance_metrics(self) -> Dict[str, Dict]:
        """Get performance metrics for all engines."""
        return self.performance_metrics.copy()
    
    def get_engine_status(self) -> Dict[str, Dict[str, Any]]:
        """Get status information for all engines."""
        status = {}
        
        for name, engine_info in self.engines.items():
            status[name] = {
                'name': name,
                'title': engine_info.title,
                'status': engine_info.status.value,
                'health': engine_info.health_status,
                'engine_type': engine_info.engine_type.value,
                'capabilities': [cap.value for cap in engine_info.capabilities],
                'inference_count': engine_info.inference_count,
                'avg_inference_time': engine_info.avg_inference_time,
                'error_count': engine_info.error_count,
                'accuracy_score': engine_info.accuracy_score,
                'memory_usage_mb': engine_info.memory_usage_mb,
                'cpu_usage_percent': engine_info.cpu_usage_percent,
                'last_inference': engine_info.last_inference.isoformat() if engine_info.last_inference else None,
                'last_health_check': engine_info.last_health_check.isoformat() if engine_info.last_health_check else None,
                'last_error': engine_info.last_error
            }
        
        return status
    
    def start_ab_test(self, test_name: str, engine_a: str, engine_b: str, 
                     traffic_split: float = 0.5) -> bool:
        """
        Start A/B testing between two engines.
        
        Args:
            test_name: Name of the A/B test
            engine_a: First engine to test
            engine_b: Second engine to test  
            traffic_split: Percentage of traffic to engine_a (0.0-1.0)
            
        Returns:
            bool: Success status
        """
        try:
            if engine_a not in self.engines or engine_b not in self.engines:
                app_log.error("One or both engines not found for A/B test")
                return False
            
            self.ab_tests[test_name] = {
                'engine_a': engine_a,
                'engine_b': engine_b,
                'traffic_split': traffic_split,
                'started_at': datetime.now(),
                'results_a': {'predictions': 0, 'total_time': 0.0, 'errors': 0},
                'results_b': {'predictions': 0, 'total_time': 0.0, 'errors': 0}
            }
            
            app_log.info(f"Started A/B test '{test_name}' between {engine_a} and {engine_b}")
            return True
            
        except Exception as e:
            app_log.error(f"Error starting A/B test: {e}")
            return False
    
    def stop_ab_test(self, test_name: str) -> Optional[Dict]:
        """Stop A/B test and return results."""
        try:
            if test_name in self.ab_tests:
                test_results = self.ab_tests[test_name].copy()
                del self.ab_tests[test_name]
                
                app_log.info(f"Stopped A/B test '{test_name}'")
                return test_results
            
            return None
            
        except Exception as e:
            app_log.error(f"Error stopping A/B test: {e}")
            return None
    
    def __del__(self):
        """Cleanup when registry is destroyed."""
        try:
            self.health_monitor_active = False
            
            # Unload all engines
            for engine_name in list(self.active_engines.keys()):
                self.unload_engine(engine_name)
                
        except Exception as e:
            app_log.error(f"Error during AI engines registry cleanup: {e}")