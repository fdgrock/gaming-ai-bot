"""
System Validation Script for Phase 3 AI Engine Modularization

This script validates the current AI system capabilities and tests
the existing components for functionality.
"""

import sys
import logging
from pathlib import Path
from datetime import datetime

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def validate_system_components():
    """Validate all system components"""
    logger.info("ğŸ” Starting Phase 3 AI Engine Modularization system validation")
    
    validation_results = {
        'ai_engines': {},
        'orchestration': {},
        'model_interface': {},
        'visualization': {},
        'registry': {},
        'overall_status': 'unknown'
    }
    
    # Test AI Engines
    logger.info("ğŸ“Š Testing AI Engines...")
    try:
        from streamlit_app.ai_engines.phase1_mathematical import MathematicalEngine
        math_engine = MathematicalEngine()
        validation_results['ai_engines']['phase1_mathematical'] = 'âœ… Available'
        logger.info("âœ… Phase 1 Mathematical Engine - Available")
        
        # Test basic functionality
        sample_data = [[1, 2, 3, 4, 5, 6] for _ in range(10)]
        insights = math_engine.get_mathematical_insights(sample_data)
        if 'high_confidence_numbers' in insights:
            validation_results['ai_engines']['phase1_mathematical'] += ' & Functional'
            logger.info("âœ… Phase 1 Mathematical Engine - Functional")
        
    except Exception as e:
        validation_results['ai_engines']['phase1_mathematical'] = f'âŒ Error: {e}'
        logger.error(f"âŒ Phase 1 Mathematical Engine - Error: {e}")
    
    try:
        from streamlit_app.ai_engines.phase2_expert_ensemble import ExpertEnsembleEngine
        expert_engine = ExpertEnsembleEngine()
        validation_results['ai_engines']['phase2_expert_ensemble'] = 'âœ… Available'
        logger.info("âœ… Phase 2 Expert Ensemble Engine - Available")
        
    except Exception as e:
        validation_results['ai_engines']['phase2_expert_ensemble'] = f'âŒ Error: {e}'
        logger.error(f"âŒ Phase 2 Expert Ensemble Engine - Error: {e}")
    
    try:
        from streamlit_app.ai_engines.phase3_set_optimizer import SetOptimizationEngine
        set_engine = SetOptimizationEngine()
        validation_results['ai_engines']['phase3_set_optimizer'] = 'âœ… Available'
        logger.info("âœ… Phase 3 Set Optimization Engine - Available")
        
    except Exception as e:
        validation_results['ai_engines']['phase3_set_optimizer'] = f'âŒ Error: {e}'
        logger.error(f"âŒ Phase 3 Set Optimization Engine - Error: {e}")
    
    try:
        from streamlit_app.ai_engines.phase4_temporal import TemporalEngine
        temporal_engine = TemporalEngine()
        validation_results['ai_engines']['phase4_temporal'] = 'âœ… Available'
        logger.info("âœ… Phase 4 Temporal Engine - Available")
        
    except Exception as e:
        validation_results['ai_engines']['phase4_temporal'] = f'âŒ Error: {e}'
        logger.error(f"âŒ Phase 4 Temporal Engine - Error: {e}")
    
    # Test Orchestration System
    logger.info("ğŸ¯ Testing Orchestration System...")
    try:
        from streamlit_app.ai_engines.prediction_orchestrator import PredictionOrchestrator
        orchestrator = PredictionOrchestrator()
        validation_results['orchestration']['prediction_orchestrator'] = 'âœ… Available'
        logger.info("âœ… Prediction Orchestrator - Available")
        
    except Exception as e:
        validation_results['orchestration']['prediction_orchestrator'] = f'âŒ Error: {e}'
        logger.error(f"âŒ Prediction Orchestrator - Error: {e}")
    
    # Test Model Interface
    logger.info("ğŸ”§ Testing Model Interface...")
    try:
        from streamlit_app.ai_engines.model_interface import BaseModel
        model_interface = BaseModel()
        validation_results['model_interface']['base_model'] = 'âœ… Available'
        logger.info("âœ… Base Model Interface - Available")
        
    except Exception as e:
        validation_results['model_interface']['base_model'] = f'âŒ Error: {e}'
        logger.error(f"âŒ Base Model Interface - Error: {e}")
    
    # Test Visualization Components
    logger.info("ğŸ“Š Testing Visualization Components...")
    try:
        from streamlit_app.components.data_visualizations import create_performance_dashboard
        validation_results['visualization']['performance_dashboard'] = 'âœ… Available'
        logger.info("âœ… Performance Dashboard - Available")
        
        # Test function with sample data
        sample_metrics = {
            'accuracy': [0.75, 0.80, 0.78, 0.82],
            'confidence': [0.70, 0.75, 0.73, 0.77]
        }
        dashboard = create_performance_dashboard(sample_metrics)
        if dashboard:
            validation_results['visualization']['performance_dashboard'] += ' & Functional'
            logger.info("âœ… Performance Dashboard - Functional")
        
    except Exception as e:
        validation_results['visualization']['performance_dashboard'] = f'âŒ Error: {e}'
        logger.error(f"âŒ Performance Dashboard - Error: {e}")
    
    # Test Engine Registry
    logger.info("ğŸ“ Testing Engine Registry...")
    try:
        from streamlit_app.ai_engines.engine_registry import get_engine_registry
        registry = get_engine_registry()
        validation_results['registry']['engine_registry'] = 'âœ… Available'
        logger.info("âœ… Engine Registry - Available")
        
        # Test registry functionality
        status = registry.get_registry_status()
        if isinstance(status, dict):
            validation_results['registry']['engine_registry'] += ' & Functional'
            logger.info("âœ… Engine Registry - Functional")
        
    except Exception as e:
        validation_results['registry']['engine_registry'] = f'âŒ Error: {e}'
        logger.error(f"âŒ Engine Registry - Error: {e}")
    
    # Calculate overall status
    successful_components = 0
    total_components = 0
    
    for category in validation_results:
        if category == 'overall_status':
            continue
        for component, status in validation_results[category].items():
            total_components += 1
            if 'âœ…' in status:
                successful_components += 1
    
    success_rate = (successful_components / total_components) * 100 if total_components > 0 else 0
    
    if success_rate >= 80:
        validation_results['overall_status'] = 'ğŸ‰ Excellent'
    elif success_rate >= 60:
        validation_results['overall_status'] = 'âœ… Good'
    elif success_rate >= 40:
        validation_results['overall_status'] = 'âš ï¸ Moderate'
    else:
        validation_results['overall_status'] = 'âŒ Poor'
    
    # Print summary
    logger.info("="*60)
    logger.info("ğŸ“‹ PHASE 3 AI ENGINE MODULARIZATION VALIDATION SUMMARY")
    logger.info("="*60)
    logger.info(f"ğŸ† Overall Status: {validation_results['overall_status']}")
    logger.info(f"ğŸ“Š Success Rate: {success_rate:.1f}% ({successful_components}/{total_components} components)")
    logger.info("")
    
    logger.info("ğŸ¤– AI Engines:")
    for engine, status in validation_results['ai_engines'].items():
        logger.info(f"   {engine}: {status}")
    
    logger.info("ğŸ¯ Orchestration:")
    for component, status in validation_results['orchestration'].items():
        logger.info(f"   {component}: {status}")
    
    logger.info("ğŸ”§ Model Interface:")
    for component, status in validation_results['model_interface'].items():
        logger.info(f"   {component}: {status}")
    
    logger.info("ğŸ“Š Visualization:")
    for component, status in validation_results['visualization'].items():
        logger.info(f"   {component}: {status}")
    
    logger.info("ğŸ“ Registry:")
    for component, status in validation_results['registry'].items():
        logger.info(f"   {component}: {status}")
    
    logger.info("="*60)
    
    return validation_results

def test_integration_workflow():
    """Test integration workflow between components"""
    logger.info("ğŸ”— Testing integration workflow...")
    
    try:
        # Test orchestrated prediction workflow
        logger.info("ğŸ¯ Testing orchestrated prediction workflow...")
        
        from streamlit_app.ai_engines.prediction_orchestrator import PredictionOrchestrator
        from streamlit_app.ai_engines.phase1_mathematical import MathematicalEngine
        
        orchestrator = PredictionOrchestrator()
        math_engine = MathematicalEngine()
        
        # Test with sample data
        sample_data = [[i, i+1, i+2, i+3, i+4, i+5] for i in range(1, 11)]
        
        # Get predictions from individual engine
        math_insights = math_engine.get_mathematical_insights(sample_data)
        
        if 'high_confidence_numbers' in math_insights:
            logger.info("âœ… Individual engine prediction successful")
            
            # Test orchestrator (basic functionality)
            try:
                orchestrator_result = orchestrator.orchestrate_predictions(
                    engines={'mathematical': math_engine},
                    historical_data=sample_data
                )
                
                if orchestrator_result and 'predictions' in orchestrator_result:
                    logger.info("âœ… Orchestrated prediction successful")
                    return True
                else:
                    logger.warning("âš ï¸ Orchestrator returned empty or invalid results")
                    return False
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Orchestrator test failed: {e}")
                return False
        else:
            logger.warning("âš ï¸ Individual engine prediction failed")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Integration workflow test failed: {e}")
        return False

def main():
    """Main validation function"""
    print("ğŸš€ Phase 3 AI Engine Modularization System Validation")
    print("=" * 70)
    
    # Run system validation
    validation_results = validate_system_components()
    
    # Run integration test
    integration_success = test_integration_workflow()
    
    # Final summary
    print("\nğŸ FINAL VALIDATION SUMMARY")
    print("=" * 40)
    print(f"System Status: {validation_results['overall_status']}")
    print(f"Integration Test: {'âœ… Passed' if integration_success else 'âŒ Failed'}")
    
    # Determine overall success
    overall_success = (
        validation_results['overall_status'] in ['ğŸ‰ Excellent', 'âœ… Good'] and
        integration_success
    )
    
    if overall_success:
        print("ğŸ‰ Phase 3 AI Engine Modularization validation SUCCESSFUL!")
        return True
    else:
        print("âš ï¸ Phase 3 AI Engine Modularization validation completed with issues.")
        print("ğŸ’¡ Recommendation: Review failed components and enhance system integration.")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)